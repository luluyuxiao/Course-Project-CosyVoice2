# Course Project: CosyVoice 2 语音合成模型复现

> 本项目基于阿里通义实验室开源的 **CosyVoice 2 (0.5B)** 模型进行了复现与应用测试，实现了 Zero-shot（零样本）语音克隆与情感控制功能。

## 1. Project 做了什么
本项目复现了一个基于 **Flow Matching (流匹配)** 和 **LLM (大语言模型)** 的先进语音合成系统。通过复现官方代码架构，实现了以下核心功能：

*   **零样本语音克隆**：输入任意 3-10 秒的参考音频（`ref2.wav`），模型即可提取其音色特征（Speaker Embedding），并生成带有该音色的全新语音。
*   **情感控制**：支持通过 Prompt 标签（如 `<|happy|>`）控制生成语音的情感色彩。
*   **多语言支持**：实现了中英日韩多语言的混合生成。

**复现工作细节**：
*   搭建了完整的推理环境，解决了 `Matcha-TTS` 第三方依赖缺失问题。
*   修复了模型配置文件中 `qwen_pretrain_path` 路径为空的 Bug，实现了模型的正确加载。
*   封装了 `src/model.py` 展示模型架构，并编写了 `src/sample.py` 用于一键推理。

## 2. 如何配置和运行环境 (Setup & Usage)

### 2.1 环境依赖
本项目在 **Python 3.10** 环境下测试通过。
主要依赖包括：`torch`, `torchaudio`, `hyperpyyaml`, `modelscope` 等。

**配置步骤：**
1.  确保已安装 Python 3.10 及以上版本。
2.  在项目根目录下安装依赖：
    ```bash
    pip install -r requirements.txt
    ```
3.  **注意**：本项目已包含 `src/third_party` 文件夹（Matcha-TTS）。如果运行报错，请检查该文件夹是否完整。

### 2.2 运行推理脚本
本项目提供了封装好的执行代码 `src/sample.py`。

1.  **准备输入**：确保项目根目录下存在参考音频文件 **`ref.wav`**。
2.  **执行命令**：
    ```bash
    python src/sample.py
    ```
3.  **模型下载**：首次运行时，脚本会自动通过 `modelscope` 下载 CosyVoice 2-0.5B 模型权重至本地缓存（约需几分钟，后续运行为秒级启动）。

## 3. 期望输出
程序运行成功后，终端将显示生成进度，并在项目根目录下生成音频文件 **`generated_cosyvoice_0.wav`**。

*   **输入配置**：
    *   参考音频：`ref.wav`
    *   输入文本：`"这是CosyVoice二代的测试，不仅能克隆音色，还能模仿情感，简直太强了！"`
    *   情感指令：`<|happy|>` (开心)

*   **输出效果**：
    *   生成的语音将完全复刻 `ref2.wav` 中的说话人音色。
    *   语音语调欢快，且保留了自然的呼吸和韵律感。
